# Adjusted README content with improved formatting and clearer explanation

adjusted_readme = """
# ğŸ§  LLM Summary-Based Document Classification

This project investigates whether LLM-generated summaries (via Gemma 2B using Ollama) can effectively replace full-text document representations for classification tasks. We compare four different approaches to representing documents:

- TF-IDF vectors
- Doc2Vec embeddings
- Extractive summaries (using TextRank)
- Abstractive summaries (via locally running LLM)

Datasets used:
- **20 Newsgroups** (mandatory)
- **AG News** (used for few-shot/zero-shot experiments)

---

## ğŸ“ Project Structure

```bash
llm_summary_classification/
â”‚
â”œâ”€â”€ data/                         # All data files
â”‚   â”œâ”€â”€ raw/                      # Original datasets
â”‚   â”œâ”€â”€ cleaned_20news.csv        # Cleaned version of 20 Newsgroups
â”‚   â”œâ”€â”€ cleaned_agnews.csv        # Cleaned version of AG News
â”‚   â”œâ”€â”€ summaries_llm.json        # Abstractive summaries via LLM
â”‚   â””â”€â”€ summaries_textrank.json   # Extractive summaries via TextRank
â”‚
â”œâ”€â”€ utils/                        # Reusable Python modules (API logic)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py            # Loading, cleaning, and saving datasets
â”‚   â”œâ”€â”€ summary_api.py            # Summary generation via LLM and TextRank
â”‚   â”œâ”€â”€ vectorization_api.py      # TF-IDF, Doc2Vec, and BERT encodings
â”‚   â”œâ”€â”€ modeling.py               # SVM, MLP, RF training functions
â”‚   â””â”€â”€ evaluation.py             # Metrics calculation and plotting
â”‚
â”œâ”€â”€ notebooks/                    # Optional test notebooks
â”‚   â”œâ”€â”€ test_vectorization.ipynb
â”‚   â””â”€â”€ test_textrank.ipynb
â”‚
â”œâ”€â”€ experiments/                  # Scripts to run training and tests
â”‚   â”œâ”€â”€ run_all_models.py         # Runs classifiers on all vector types
â”‚   â””â”€â”€ few_shot_test.py          # Few-shot/zero-shot scenario evaluation
â”‚
â”œâ”€â”€ outputs/                      # Store results and evaluation plots
â”‚   â”œâ”€â”€ metrics_20news.json
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ confusion_svm.png
â”‚       â””â”€â”€ runtime_plot.png
â”‚
â”œâ”€â”€ requirements.txt              # Project dependencies
â”œâ”€â”€ README.md                     # Project documentation (this file)
â””â”€â”€ project_plan.pdf              # Full technical project plan
```
##  Key Files to Know

- **`data_loader.py`**  
  Loads and cleans both datasets (20 Newsgroups and AG News). Prepares them for summarization and vectorization.

- **`summary_api.py`**  
  Generates summaries using:
  - **Gemma 2B** (via Ollama) for abstractive summarization  
  - **TextRank** (via `sumy`) for extractive summarization

- **`vectorization_api.py`**  
  Converts documents or summaries into vector form using:
  - **TF-IDF** (`scikit-learn`)  
  - **Doc2Vec** (`gensim`)  
  - **Sentence-BERT** (`sentence-transformers`)

- **`modeling.py`**  
  Trains and tests classification models:
  - Support Vector Machine (SVM)  
  - Multi-Layer Perceptron (MLP)  
  - Random Forest

- **`evaluation.py`**  
  Computes classification metrics:
  - Accuracy, Precision, Recall, F1-score  
  - Generates confusion matrices and runtime plots

- **`run_all_models.py`**  
  Executes the full ML pipeline on all document representations and saves evaluation results for comparison.
